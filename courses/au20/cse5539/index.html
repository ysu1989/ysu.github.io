<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" />
<title>SP20: CSE5243</title>
</head>


<body class="html front not-logged-in one-sidebar sidebar-first page-node" data-twttr-rendered="true">

  				
<div>
<h1><strong>CSE 5539: Cutting-Edge Topics in Natural Language Processing (AU20, Wed 10:00-11:50am, Zoom)</strong></h1>
<p><span style="font-size: medium"><span style="text-align: justify"><strong>Instructor</strong>: <a href=http://ysu1989.github.io/>Yu Su</a> </span></span></p>
<p><span style="font-size: medium"><span style="text-align: justify"><strong>Level and credits</strong>: U/G, 2</span></span></p>
<p><span style="font-size: medium"><span style="text-align: justify"><strong>Prerequisites</strong>: CSE 3521/5521/5243/5525 highly recommended; requires solid understanding of machine/deep learning and natural language processing for meaningful participation</span></span></p>
<!-- <p><span style="font-size: medium"><span style="text-align: justify"><strong>Office hours and locations (Instructor)</strong>: <span style="color: #0000FF">Fri 11:00AM-12:15PM, Dreese Labs 783</span></span></span></p> -->
</div>

<h3 property="dc:title" datatype="" style="color: #990000"><strong>Description</strong></h3>
<p><span style="font-size: medium"><span style="text-align: justify">
Paper-driven discussion of cutting-edge topics in natural language processing with a focus on pre-trained language models (BERT*, GPT-3, probing), language interfaces (dialogue systems, semantic parsing, question answering, and robot instruction following), and knowledge bases (construction and reasoning), and more. 
</span></span></p>
	
<div>
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Grading Plan </strong></h3>
<ul><span style="font-size: medium">
<li></strong><span style="font-size: medium">Participation (including paper presentation and participation in in-class and online discussions): 50%</strong></li>
<li></strong><span style="font-size: medium">Course project: 50%</strong></li>
</span>
</ul>
</div>

<div style="font-size: medium">
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Textbooks</strong></h3>
No required textbook. Recommended books for reading: 
<ul>
<li>Introduction to Natural Language Processing, 1st edition, Jacob Eisenstein. <a href="https://mitpress.mit.edu/books/introduction-natural-language-processing">Official version</a>, <a href="https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf">online version</a></li>
<li>Speech and Language Processing, 2nd or 3rd edition, Dan Jurafsky and James H. Martin. <a href="https://www.amazon.com/Speech-Language-Processing-Daniel-Jurafsky/dp/0131873210">2nd edition</a>, <a href="https://web.stanford.edu/~jurafsky/slp3/">3rd edition (draft)</a> </li>
<li>Deep Learning, 1st edition, Ian Goodfellow and Yoshua Bengio and Aaron Courville. <a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?ie=UTF8&qid=1472485235&sr=8-1&keywords=deep+learning+book">Official version</a>, <a href="https://www.deeplearningbook.org/">online version</a></li>
<li>Artificial Intelligence: A Modern Approach, 3rd edition, Stuart Russell and Peter Norvig. <a href="https://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597">Official version</a></li>
<li>Find latest advancements at NLP/AI conferences/journals: ACL, EMNLP, NAACL, TACL, NeurIPS, ICML, ICLR, AAAI</li>
</ul>
</div>

<div style="font-size: medium">
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Health and Safety Statement</strong></h3>
<p>See <a href="./health_and_safety_statement.pdf">here</a>.</p>
</div>

<div style="font-size: medium">
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Academic Integrity Policy</strong></h3>
<p>Academic integrity is essential to maintaining an environment that fosters excellence in teaching, research, and other educational and scholarly activities. Thus, The Ohio State University and the Committee on Academic Misconduct (COAM) expect that all students have read and understand the University’s <a href="https://trustees.osu.edu/index.php?q=rules/code-of-student-conduct/">Code of Student Conduct</a>, and that all students will complete all academic and scholarly assignments with fairness and honesty. Students must recognize that failure to follow the rules and guidelines established in the University’s <a href="https://trustees.osu.edu/index.php?q=rules/code-of-student-conduct/">Code of Student Conduct</a> and this syllabus may constitute “Academic Misconduct.” For more info, click <a href="https://oaa.osu.edu/coamfaqs.html">here</a>.</p>
</div>

<!-- <div style="font-size: medium">
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Anonymous Feedback/Comments/Suggestions?</strong></h3>
<p>Feel free to leave any comments and suggestions about how the instructor/grader can do better to help you learn this course, such as whether the lectures are clear, examples are helpful, questions are answered timely, etc. Please check <a href="https://goo.gl/forms/aVF9hrOWao5yFbOC2">this anonymous form</a>. Your input is highly appreciated! ;-)</p>
<div> -->

<div>
<h3 property="dc:title" datatype="" style="color: #990000"><strong>Course Syllabus and Schedule (Tentative)</strong></h3>
<head>
<style>
table, th, td {
    border: 1px solid black;
}
</style>
</head>

<body>
<table style="width:100%">
  <tr>
    <td>Week</td>
    <td>Date</td>
    <td>Topic</td> 
    <td>Assignment Out</td>
    <td>Assignment Due</td>
    <td>Lecture Notes</td>
  </tr>
  <tr>
    <td>1</td>
    <td>08/26</td>
    <td>Class outline</a></td> 
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>2</td>
    <td>09/02</td>
    <td>
      - Course project [<a href="02project.pdf">slides</a>]<br>
      - Attention is All You Need [<a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">paper</a>] [<a href="Transformer.pdf">slides</a>] <br>
      - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [<a href="https://arxiv.org/abs/1810.04805">paper</a>] [<a href="BERT.pdf">slides</a>]
    </td> 
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>3</td>
    <td>09/09</td>
    <td>
      - DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter [<a href="https://arxiv.org/abs/1910.01108">paper</a>] [<a href="DistilBERT.pdf">slides</a>] <br>
      - BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension [<a href="https://www.aclweb.org/anthology/2020.acl-main.703/">paper</a>] [<a href="BART.pdf">slides</a>]
    </td> 
    <td></td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>4</td>
    <td>09/16</td>
    <td>
      - Longformer: The Long-Document Transformer [<a href="https://arxiv.org/abs/2004.05150">paper</a>] [<a href="#">slides</a>] <br>
      - Big Bird: Transformers for Longer Sequences [<a href="https://arxiv.org/pdf/2007.14062.pdf">paper</a>] [<a href="#">slides</a>]
    </td> 
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>5</td>
    <td>09/23</td>
    <td>
      - Language Models are Few-Shot Learners [<a href="https://arxiv.org/abs/2005.14165">paper</a>] [<a href="#">slides</a>]
    </td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>6</td>
    <td>09/30</td>
    <td>Project proposal</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>7</td>
    <td>10/07</td>
    <td>Language interfaces: dialogue systems and semantic parsing</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>8</td>
    <td>10/14</td>
    <td>Language interfaces: dialogue systems and semantic parsing</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>9</td>
    <td>10/21</td>
    <td>Language interfaces: dialogue systems and semantic parsing</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>10</td>
    <td>10/28</td>
    <td>Knowledge bases: construction and reasoning</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>11</td>
    <td>11/04</td>
    <td>Knowledge bases: construction and reasoning</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>12</td>
    <td>11/11</td>
    <td>Veterans Day observed - no class</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>13</td>
    <td>11/18</td>
    <td>Knowledge bases: construction and reasoning</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>14</td>
    <td>11/25</td>
    <td>Project presentation</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>15</td>
    <td>12/02</td>
    <td>Project presentation</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</table>
</body>
</div>

</body></html>
